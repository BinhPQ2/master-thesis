{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e91e0ff",
   "metadata": {},
   "source": [
    "# Define data/result directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c880f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder = \"../data\"\n",
    "result_folder = \"../results\"\n",
    "manga_list = \"vi/Ruri Dragon (Oneshot)/Ch. None\"  # Will be changed to list later\n",
    "\n",
    "# Ruri Dragon\n",
    "manga_folder = os.path.join(data_folder, manga_list)\n",
    "\n",
    "individual_result_folder = os.path.join(result_folder, manga_list)\n",
    "json_output_dir = os.path.join(individual_result_folder, \"json_results\")\n",
    "result_image_output_dir = os.path.join(individual_result_folder, \"image_results\")\n",
    "\n",
    "cut_texts_dir = os.path.join(individual_result_folder, \"cut_texts\")\n",
    "\n",
    "raw_images = os.listdir(manga_folder)\n",
    "json_files = os.listdir(json_output_dir)\n",
    "easy_ocr_viet_ocr_result_dir = os.path.join(\n",
    "    individual_result_folder, \"easy_ocr_viet_ocr_result\"\n",
    ")\n",
    "os.makedirs(easy_ocr_viet_ocr_result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542b3f",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e4084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\easyocr-vietocr\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from vietocr.tool.config import Cfg\n",
    "\n",
    "# Initialize EasyOCR (Vietnamese)\n",
    "reader = easyocr.Reader([\"vi\"])\n",
    "\n",
    "config = Cfg.load_config_from_name(\"vgg_transformer\")  # Load YAML config file\n",
    "from vietocr.tool.predictor import Predictor\n",
    "\n",
    "config[\"weights\"] = \"../models/viet_ocr/pretrained_weight/vgg_transformer.pth\"\n",
    "# config['weights'] = \"../models/viet_ocr/custom_weight/transformerocr-1.pth\"\n",
    "config[\"cnn\"][\"pretrained\"] = False\n",
    "detector = Predictor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved result for 04.json ‚Üí ../results\\vi/Ruri Dragon (Oneshot)/Ch. None\\easy_ocr_viet_ocr_result\\04.json\n"
     ]
    }
   ],
   "source": [
    "# Experimental function code, havent test yet\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_transcript_from_image(img_path, reader, detector):\n",
    "    \"\"\"\n",
    "    Run OCR pipeline on a single cropped image:\n",
    "    1. Use EasyOCR to detect line regions\n",
    "    2. Use VietOCR to recognize each cropped line\n",
    "    3. Return merged transcript (string)\n",
    "    \"\"\"\n",
    "    results = reader.readtext(img_path, detail=1, paragraph=False)\n",
    "\n",
    "    if not results:\n",
    "        return \"\"  # no text detected\n",
    "\n",
    "    line_texts = []\n",
    "    for coords, _, _ in results:  # coords = [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]\n",
    "        x_min = min([pt[0] for pt in coords])\n",
    "        y_min = min([pt[1] for pt in coords])\n",
    "        x_max = max([pt[0] for pt in coords])\n",
    "        y_max = max([pt[1] for pt in coords])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        cropped = img.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "        try:\n",
    "            text_viet = detector.predict(cropped)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è VietOCR failed on {img_path}: {e}\")\n",
    "            text_viet = \"\"\n",
    "\n",
    "        if text_viet.strip():\n",
    "            line_texts.append(text_viet)\n",
    "\n",
    "    return \" \".join(line_texts)\n",
    "\n",
    "\n",
    "def process_json_file(\n",
    "    json_file,\n",
    "    json_output_dir,\n",
    "    cut_texts_dir,\n",
    "    easy_ocr_viet_ocr_result_dir,\n",
    "    reader,\n",
    "    detector,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process one JSON file:\n",
    "    - Load original annotations\n",
    "    - Replace essential text OCR results with EasyOCR+VietOCR pipeline output\n",
    "    - Save updated JSON to result folder\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(json_file)[0]\n",
    "    json_path = os.path.join(json_output_dir, json_file)\n",
    "    cut_page_dir = os.path.join(cut_texts_dir, base_name)\n",
    "\n",
    "    if not os.path.exists(cut_page_dir):\n",
    "        print(f\"‚ö†Ô∏è No cut_texts found for {json_file}, skipping...\")\n",
    "        return\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_ocr = []\n",
    "    for idx, (bbox, is_essential) in enumerate(\n",
    "        zip(data[\"texts\"], data[\"is_essential_text\"])\n",
    "    ):\n",
    "        if not is_essential:\n",
    "            new_ocr.append(data[\"ocr\"][idx])\n",
    "            continue\n",
    "\n",
    "        cut_img_path = os.path.join(cut_page_dir, f\"{base_name}_{idx:03}.png\")\n",
    "        if not os.path.exists(cut_img_path):\n",
    "            print(f\"‚ö†Ô∏è Missing cut image {cut_img_path}, keeping original OCR.\")\n",
    "            new_ocr.append(data[\"ocr\"][idx])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            vi_text = get_transcript_from_image(cut_img_path, reader, detector)\n",
    "            if not vi_text:\n",
    "                vi_text = data[\"ocr\"][idx]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR pipeline failed for {cut_img_path}: {e}\")\n",
    "            vi_text = data[\"ocr\"][idx]\n",
    "\n",
    "        new_ocr.append(vi_text)\n",
    "\n",
    "    data[\"ocr\"] = new_ocr\n",
    "\n",
    "    out_path = os.path.join(easy_ocr_viet_ocr_result_dir, json_file)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Saved result for {json_file} ‚Üí {out_path}\")\n",
    "\n",
    "\n",
    "for json_file in json_files:\n",
    "    if json_file.endswith(\".json\"):\n",
    "        process_json_file(\n",
    "            json_file,\n",
    "            json_output_dir,\n",
    "            cut_texts_dir,\n",
    "            easy_ocr_viet_ocr_result_dir,\n",
    "            reader,\n",
    "            detector,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b92de4",
   "metadata": {},
   "source": [
    "Individual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8409620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_006.png: ·ª™, TR√îNG CON GI·ªêNG H·ªÜT B·ªê CON ƒê·∫§Y\n",
      "04_001.png: V√å CON L√Ä CON LAI GI·ªÆA NG∆Ø·ªúI V√Ä R·ªíNG.\n",
      "05_004.png: B√åNH Tƒ®NH N√ÉO, ƒê·∫¶U PH·∫¢I N√ì S·∫º GI·∫æT CON HAY G√å ƒê√ÇU\n",
      "vnexpress.png: M·ªôt ph·∫ßn nguy√™n nh√¢n khi·∫øn M·ªπ kh√¥ng nƒÉm ƒë∆∞·ª£c v·ª• Israel t·∫≠p k√≠ch l√£nh th·ªï Qatar l√† do t·∫≠p trung gi√°m s√°t n∆°i kh√°c, theo quan ch·ª©c CENTCOM. \"ƒê√≤n t·∫•n c√¥ng c·ªßa Israel nh·∫±m v√†o m·ª•c ti√™u Hamas ·ªü Qatar ho√†n to√†n kh√¥ng c√≥ d·∫•u hi·ªáu hay c·∫£nh b√°o tr∆∞·ªõc, v√¨ to√†n b·ªô ph∆∞∆°ng ti·ªán gi√°m s√°t v√† s·ª± ch√∫ √Ω c·ªßa ch√∫ng t√¥i ƒë·ªÅu kh√¥ng n·∫±m ·ªü ƒë√≥. Kh√¥ng ai nghƒ© ƒëi·ªÅu n√†y s·∫Ω di·ªÖn ra\", t∆∞·ªõng Derek France, ch·ªâ huy l·ª±c l∆∞·ª£ng kh√¥ng qu√¢n thu·ªôc B·ªô t∆∞ l·ªánh Trung t√¢m M·ªπ (CENTCOM), cho bi·∫øt h√¥m 24/9. CENTCOM l√† ƒë∆°n v·ªã ƒë·∫∑c tr√°ch to√†n b·ªô ho·∫°t ƒë·ªông c·ªßa qu√¢n ƒë·ªôi M·ªπ t·∫°i Trung ƒê√¥ng. Ph√°t bi·ªÉu ƒë∆∞·ª£c t∆∞·ªõng France ƒë∆∞a ra trong bu·ªïi th·∫£o lu·∫≠n v·ªÅ h·ªá qu·∫£ c·ªßa cu·ªôc t·∫≠p k√≠ch c·ªßa Israel nh·∫£m v√†o th·ªß ƒë√¥ Doha c·ªßa Qatar h·ªìi ƒë·∫ßu th√°ng, S·ª± vi·ªác khi·∫øn nhi·ªÅu ng∆∞·ªùi ƒë·∫∑t c√¢u h·ªèi t·∫°i sao l∆∞·ªõi ph√≤ng kh√¥ng, c·∫£m bi·∫øn ti√™n ti·∫øn c·ªßa M·ªπ v√† Qatar kh√¥ng ph√°t hi·ªán v√† ƒë√°nh ch·∫∑n m·ªëi ƒëe d·ªça. Tr√†ng\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_image_dir = \"../data/vi/test_data/multiple_line\"\n",
    "test_images = os.listdir(test_image_dir)\n",
    "\n",
    "for test_image in test_images:\n",
    "    img_path = os.path.join(test_image_dir, test_image)\n",
    "\n",
    "    # üîÑ Reuse the function\n",
    "    final_text = get_transcript_from_image(img_path, reader, detector)\n",
    "\n",
    "    print(f\"{test_image}: {final_text if final_text else '(empty)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d191b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04_001.png: V√å CON L√Ä\n",
      "05_004.png: B√åNH Tƒ®NH\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_image_dir = \"../data/vi/test_data/one_line\"\n",
    "test_images = os.listdir(test_image_dir)\n",
    "\n",
    "for test_image in test_images:\n",
    "    img_path = os.path.join(test_image_dir, test_image)\n",
    "\n",
    "    # üîÑ Reuse the function\n",
    "    final_text = get_transcript_from_image(img_path, reader, detector)\n",
    "\n",
    "    print(f\"{test_image}: {final_text if final_text else '(empty)'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyocr-vietocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
